# Use the official Ollama Docker image as the base
FROM ollama/ollama:latest

# Start Ollama server in the background and preload models
RUN nohup ollama serve & \
    sleep 5 && \
    ollama pull llama3.2:3b && \
    ollama pull mxbai-embed-large && \
    kill $(pgrep ollama)

# Expose the Ollama server port
EXPOSE 11434


